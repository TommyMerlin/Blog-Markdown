---
title: 卷积神经网络
date: 2020-02-28 14:42:19
tags:
- 机器学习
- 卷积神经网络
categories:
- 机器学习
mathjax: true
---

## 1.卷积神经网络结构 

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84-34f076.png" width="70%">

 - **输入层**：将每个像素代表一个特征节点输入到网络中。
 - **卷积层**：卷积运算的主要目的是使原信号特征增强，并降低噪音。
 - **降采样层**：降低网络训练参数及模型的过拟合程度。
 - **全连接层**：对生成的特征进行加权。

<!-- more -->

## 2.卷积运算

 - 1.**求点积**：将5×5输入矩阵中3×3深蓝色区域中每个元素分别与其对应位置的权值（红色数字）相乘，然后再相加，所得到的值作为3×3输出矩阵（绿色）的第一个元素。  
 - 2.**滑动窗口**：将3×3权值矩阵向右移动一个格（即，步长为1）。  
 - 3.**重复操作**：同样地，将此时深色区域内每个元素分别与对应的权值相乘然后再相加，所得到的值作为输出矩阵的第二个元素；重复上述“求点积-滑动窗口”操作，直至输出矩阵所有值被填满。

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-%E5%8D%B7%E7%A7%AF%E6%93%8D%E4%BD%9C-50824a.png" width="60%">

**注意点**：

 - 卷积核在2 维输入数据上“滑动”，对当前输入部分的元素进行矩阵乘法，然后将结果汇为单个输出像素值，重复这个过程直到遍历整张图像，这个过程就叫做卷积  
 - 这个权值矩阵就是**卷积核**  
 - 卷积操作后的图像称为**特征图**（feature map）

## 3.全连接层和卷积层对比

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-%E5%85%A8%E8%BF%9E%E6%8E%A5%E5%B1%82%E5%92%8C%E5%8D%B7%E7%A7%AF%E5%B1%82%E5%AF%B9%E6%AF%94-effbe8.png" width="60%">

## 4.卷积的作用

 - 卷积运算的主要目的是**使原信号特征增强，并降低噪音**。  
 - 对图像用一个卷积核进行卷积运算，实际上是一个滤波的过程。每个卷积核都是一种特征提取方式，就像是一个筛子，将图像中符合条件的部分筛选出来。  

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-%E5%8D%B7%E7%A7%AF%E7%A4%BA%E6%84%8F%E5%9B%BE-f7467d.png" width="50%">

## 5.填充（Padding）

在卷积核滑动过程中图像边缘会被裁剪掉，将5×5的特征矩阵转换为3×3的特征矩阵。  
**填充**：用额外的“假”像素（通常值为0）填充边缘。这样，在滑动时的卷积核可以允许原始边缘像素位于卷积核的中心，同时延伸到边缘之外的假像素，从而产生与输入（5×5蓝色）相同大小的输出（5×5绿色）。  

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-%E5%A1%AB%E5%85%85-8adfab.png" width="20%">

## 6.多通道卷积

 - 每个卷积核都会将图像生成为另一幅特征映射图，即：**一个卷积核提取一种特征**。  
 - 为了使特征提取更充分，可以添加多个卷积核以提取不同的特征，也就是，**多通道卷积**。  

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-%E7%89%B9%E5%BE%81%E7%AD%9B%E9%80%89-cbf16f.png" width="20%">

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-23-%E5%A4%9A%E9%80%9A%E9%81%93%E5%8D%B7%E7%A7%AF-5e103c.png" width="40%">

## 7.池化（pooling）

**池化**：计算图像一个区域上的某个特定特征的平均值或最大值的聚合操作。  
卷积层的作用是探测上一层特征的局部连接，而池化的作用是**在语义上将相似的特征合并起来**，从而达到降维的目的。  

**常用池化方法**

 - 1.**均值池化**：对池化区域内的像素点取均值，这种方法得到的特征数据对背景信息更敏感。  
 - 2.**最大池化**：对池化区域内所有像素点取最大值，这种方法得到的特征对纹理特征信息更加敏感。

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-%E6%9C%80%E5%A4%A7%E6%B1%A0%E5%8C%96-412c09.png" width="40%">

## 8.步长（stride）

**步长**：卷积核在图片上移动的格数。  

 - stride=1：

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-stride1-f73006.png" width="50%">

 - stride=2:

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-stride2-7ab9fe.png" width="50%">

步长大于1的卷积操作也是**降维的一种方式**。    
卷积后图片尺寸：假如步长为S，原始图片尺寸为$[N_1,N_1]$，卷积核大小为$[N_2,N_2]$，那么**卷积之后图像大小**：
$[\frac{N_1-N_2}{S}+1,\frac{N_1-N_2}{S}+1]$

## 9.卷积神经网络组成小结

<img style="float: center;" src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BB%84%E6%88%90-cd203f.png" width="50%">

正则表达式：
输入层→(卷积层+→池化层?)+→全连接层+  
含义：**输入层**→(**卷积层**[一层或多层]+**池化层**[0或1层])[一个或多个]→**全连接层**[一个或多个]

## 10.Tensorflow实践

CIFAR10 数据集

<img src="https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-CIFAR10-a4389d.png" alt="CIFAR10" width="40%" />


```python
import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
import pickle as p
%load_ext tensorboard
```

### 9.1 导入CIFAR数据集

```python
(Xtrain,Ytrain),(Xtest,Ytest) = tf.keras.datasets.cifar10.load_data()
```


```python
# 查看训练和测试数据集大小
print("Xtrain's shape:",Xtrain.shape)
print("Ytrain's shape:",Ytrain.shape)
print("Xtest's shape:",Xtest.shape)
print("Ytest's shape:",Ytest.shape)
```

    Xtrain's shape: (50000, 32, 32, 3)
    Ytrain's shape: (50000, 1)
    Xtest's shape: (10000, 32, 32, 3)
    Ytest's shape: (10000, 1)

```python
# 查看图像数据和标签
label_dict = {0:'T-shirt/top',1:'Trouser',2:'Pullover',3:'Dress',4:'Coat',
             5:'Sandal',6:'Shirt',7:'Sneaker',8:'Bag',9:'Ankle boot'}
def plot_images_labels(images,labels,prediction,idx,num=10):
    fig = plt.figure(figsize=(12,6))
    labels = np.array(labels)
    if num>10:
        num=10
    for i in range(0,10):
        plt.subplot(2,5,1+i)
        plt.imshow(images[idx],cmap='binary')
        title=str(i+1)+'.'+label_dict[labels[idx,0]]
        if len(prediction)>0:
            title+='=>'+label_dict[prediction[idx]]
        plt.title(title,fontsize=10)
        idx+=1
plot_images_labels(Xtest,Ytest,[],10,10)
```


![](https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-output_16_0-5e9bb4.png)


### 9.2 数据预处理


```python
# 图像数据数字标准化
Xtrain_norm = Xtrain.astype('float32')/255.0
Xtest_norm = Xtest.astype('float32')/255.0
```


```python
# 独热编码
# Ytrain_onehot = tf.one_hot(Ytrain,depth=10)
# Ytest_onehot = tf.one_hot(Ytest,depth=10)
```

### 9.3 建立模型


```python
model = tf.keras.Sequential()
model.add(tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
model.add(tf.keras.layers.MaxPooling2D((2, 2)))
model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))
model.add(tf.keras.layers.MaxPooling2D((2, 2)))
model.add(tf.keras.layers.Conv2D(64, (3, 3), activation='relu'))
model.add(tf.keras.layers.Flatten())
model.add(tf.keras.layers.Dense(64, activation='relu'))
model.add(tf.keras.layers.Dense(10, activation='softmax'))
model.summary()
```

    Model: "sequential_18"
    _________________________________________________________________
    Layer (type)                 Output Shape              Param #   
    =================================================================
    conv2d_35 (Conv2D)           (None, 30, 30, 32)        896       
    _________________________________________________________________
    max_pooling2d_12 (MaxPooling (None, 15, 15, 32)        0         
    _________________________________________________________________
    conv2d_36 (Conv2D)           (None, 13, 13, 64)        18496     
    _________________________________________________________________
    max_pooling2d_13 (MaxPooling (None, 6, 6, 64)          0         
    _________________________________________________________________
    conv2d_37 (Conv2D)           (None, 4, 4, 64)          36928     
    _________________________________________________________________
    flatten_12 (Flatten)         (None, 1024)              0         
    _________________________________________________________________
    dense_22 (Dense)             (None, 64)                65600     
    _________________________________________________________________
    dense_23 (Dense)             (None, 10)                650       
    =================================================================
    Total params: 122,570
    Trainable params: 122,570
    Non-trainable params: 0
    _________________________________________________________________


### 9.4 编译模型

```python
# 模型编译
model.compile(optimizer='adam',
             loss='sparse_categorical_crossentropy',
             metrics=['accuracy'])
```


```python
import datetime
log_dir = "F:\\JupyterNotebook\\TensorFlowLearn\\logs\\" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)
```

### 9.5 训练模型

```python
# 训练模型
his = model.fit(Xtrain_norm,Ytrain,epochs=5,validation_data=(Xtest_norm,Ytest),callbacks=[tensorboard_callback])
```

    Train on 50000 samples, validate on 10000 samples
    Epoch 1/5
       32/50000 [..............................] - ETA: 8:18 - loss: 2.3121 - accuracy: 0.0312WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (0.103193). Check your callbacks.
    50000/50000 [==============================] - 23s 452us/sample - loss: 1.5411 - accuracy: 0.4347 - val_loss: 1.2904 - val_accuracy: 0.5303
    Epoch 2/5
    50000/50000 [==============================] - 22s 440us/sample - loss: 1.1496 - accuracy: 0.5928 - val_loss: 1.1249 - val_accuracy: 0.6020
    Epoch 3/5
    50000/50000 [==============================] - 22s 449us/sample - loss: 0.9963 - accuracy: 0.6501 - val_loss: 0.9654 - val_accuracy: 0.6617
    Epoch 4/5
    50000/50000 [==============================] - 23s 455us/sample - loss: 0.8942 - accuracy: 0.6858 - val_loss: 0.9129 - val_accuracy: 0.6794
    Epoch 5/5
    50000/50000 [==============================] - 23s 455us/sample - loss: 0.8187 - accuracy: 0.7118 - val_loss: 0.9052 - val_accuracy: 0.6840

```python
his.history.keys()
```


    dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])

### 9.6 训练结果

模型训练后的准确率为**68.4%**。


```python
plt.plot(his.epoch,his.history.get('loss'),label='trainset_loss')
plt.plot(his.epoch,his.history.get('val_loss'),label='testset_loss')
plt.legend(fontsize=12)
```


![](https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-output_26_1-7effca.png)

```python
plt.plot(his.epoch,his.history.get('accuracy'),label='trainset_accuracy')
plt.plot(his.epoch,his.history.get('val_accuracy'),label='testset_accuracy')
plt.legend(fontsize=12)
```


![](https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-output_27_1-79ce03.png)

```python
prediction = model.predict(Xtest_norm)
prediction = np.argmax(prediction,axis=1)
```


```python
plot_images_labels(Xtest,Ytest,prediction,10,10)
```


![](https://aliyun-oss-coderhuye.oss-cn-hangzhou.aliyuncs.com/blog/2021-06-19-output_29_0-079ae7.png)

可见第1和第6幅图预测错误，本次训练只进行了5轮，仍有比较大的改进空间。