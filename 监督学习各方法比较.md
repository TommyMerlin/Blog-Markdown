---
title: 监督学习各方法比较
date: 2020-01-09 19:20:00
tags:
- 机器学习
- 统计学习方法
- 监督学习
categories:
- 机器学习
- 统计学习方法
mathjax: true
---

## 1.感知机
### 优点
 - 模型简单易懂，便于编程实现；
 - 是许多后续算法如SVM、神经网络、深度学习的基础。

### 缺点
 - 只能对线性可分数据集进行学习；
 - 不同参数设置会学到不同模型，泛化能力好差。

<!-- more -->

## 2.k近邻法

### 优点
-   理论成熟，思想简单，既可以用来做分类也可以用来做回归；
-   可用于非线性分类，可以生成任意形状的决策边界；
-   训练时间复杂度为O(n)，因为是消极的学习方法不需要建立模型；
-   对数据没有假设，准确度高，对outlier（离群值、逸出值）不敏感；
-   基于局部信息进行预测，正因为这样而局部分类决策，KNN（k很小时）对噪声非常敏感。

### 缺点
-   计算量大（体现在距离计算上），因为需要逐个计算测试样例和训练样例之间的而相似度；  
-   样本不平衡问题（即有些类别的样本数量很多，而其它样本的数量很少）效果差；   
-   需要大量内存；  
-   除非采用适当的邻近性度量k和数据预处理，否则最近邻分类器可能做出错误的预测。

## 3.朴素贝叶斯法
### 优点
-   有坚实的数学基础，以及稳定的分类效率；
-   对小规模的数据表现很好，能个处理多分类任务，适合增量式训练；
-   面对孤立的噪声点，朴素贝叶斯分类器是健壮的。通过在建模和分类时忽略样例，朴素贝叶斯法对缺失数据不太敏感，算法也比较简单，常用于文本分类；
-   面对无关属性，朴素贝叶斯法是健壮的。如果 $X_i$ 是无关属性，那么 $P(X_i,Y_i)$ 几乎变成了均匀分布。 $X_i$ 的类条件概率不会对总的后验概率的计算产生影响。

### 缺点
-   需要计算先验概率；
-   分类决策存在错误率；
-   对输入数据的表达形式很敏感；
-   输入变量必须都是条件独立的，如果假设它们之间存在概率依存关系，模型就变成了贝叶斯网，相关属性可能会降低朴素贝叶斯分类器的性能。

## 4.决策树
### 优点
-   计算简单，易于理解，可解释性强；
-   比较适合处理有缺失属性的样本；
-   能够处理不相关的特征；
-   在相对短的时间内能够对大型数据源做出可行且效果良好的结果。

### 缺点
-   容易发生过拟合（随机森林可以很大程度上减少过拟合），剪枝是解决决策树过拟合并缩小决策树的方法之一；
-   忽略了数据之间的相关性；
-   对于那些各类别样本数量不一致的数据，在决策树当中,信息增益的结果偏向于那些具有更多数值的特征（只要是使用了信息增益，都有这个缺点，如RF）。

## 5.支持向量机

### 优点

-   可以解决高维问题，即大型特征空间；
-   能够处理非线性特征的相互作用；
-   无需依赖整个数据；
-   可以提高泛化能力。

### 缺点

-   当观测样本很多时，效率并不是很高，因为在大数据中，SVM时间复杂度为![[公式]](https://www.zhihu.com/equation?tex=O%28n%5E%7B3%7D%29+)；
-   对非线性问题没有通用解决方案，有时候很难找到一个合适的核函数；
-   在噪声过多的情况下，SVM容易造成过拟合；
-   类严重重叠时，SVM的表现也很差；
-   对缺失数据敏感。

## 6.逻辑斯谛回归

### 优点

-   实现简单，广泛的应用于工业问题上；
-   分类时计算量非常小，速度很快，存储资源低；
-   便利的观测样本概率分数；
-   对逻辑回归而言，多重共线性并不是问题，它可以结合L2正则化来解决该问题。

### 缺点

-   当特征空间很大时，逻辑回归的性能不是很好；
-   容易欠拟合，一般准确度不太高；
-   不能很好地处理大量多类特征或变量。
-   只能处理两分类问题（在此基础上衍生出来的softmax可以用于多分类），且必须**线性可分**；
-   对于非线性特征，需要进行转换。

## 7.提升方法AdaBoost算法

### 优点

-   Adaboost是一种有很高精度的分类器；
-   可以使用各种方法构建子分类器，Adaboost算法提供的是框架；
-   当使用简单分类器时，计算出的结果是可以理解的，并且弱分类器的构造极其简单；
-   简单，不用做特征筛选；
-   不易发生overfitting。

### 缺点

-   对outlier比较敏感。

## 8.人工神经网络

### 优点

-   分类的准确度高；
-   并行分布处理能力强,分布存储及学习能力强；
-   对噪声神经有较强的鲁棒性和容错能力，能充分逼近复杂的非线性关系；
-   具备联想记忆的功能；
-   ANN可以处理冗余特征，因为权值在训练过程中自动学习。冗余特征的权值非常小；
-   测试样例分类时非常快。

### 缺点

-   神经网络需要大量的参数，如网络拓扑结构、权值和阈值的初始值；
-   不能观察之间的学习过程，输出结果难以解释，会影响到结果的可信度和可接受程度；
-   学习时间过长,特别是当隐藏结点数量很大时，甚至可能达不到学习的目的。
-   ANN权值学习使用的梯度下降方法经常会收敛到局部最优解。避免局部最优解的方法: 在权值更新公式中加上一个冲量（momentum term）；使用高价的导数；随机优化思想